{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "collapsed_sections": [
        "hjZW-G4X4SoM",
        "l_Hu0iTdrNpi",
        "5Fp37V2ahpdn",
        "ySjbwhfGl9sm",
        "-BLOTGo7jQhC",
        "0xtu6axtlube",
        "vDcFZqvfnEOn",
        "XaDOSYrdk-Y0",
        "ZFSgMIHza5st"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MY3UGuhyYSu7"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import random\n",
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Resources\n",
        "\n",
        "* Keras functional API: https://keras.io/guides/functional_api/"
      ],
      "metadata": {
        "id": "VnqyeCcimZel"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Datasets"
      ],
      "metadata": {
        "id": "E2XxKK313tFP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Image generator\n",
        "\n",
        "* https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image/ImageDataGenerator"
      ],
      "metadata": {
        "id": "hjZW-G4X4SoM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
        "x_train = tf.expand_dims(x_train, axis=-1)\n",
        "x_test = tf.expand_dims(x_test, axis=-1)"
      ],
      "metadata": {
        "id": "i0hoWmpom1MM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img_gen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
        "    horizontal_flip=True,\n",
        "    rescale=1/255.0,\n",
        "    shear_range=0.2,\n",
        ")\n",
        "img_gen.fit(x_train)\n",
        "generator = img_gen.flow(x_train, y_train)"
      ],
      "metadata": {
        "id": "OOPddBzO4MWj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_batch, y_batch = next(generator)"
      ],
      "metadata": {
        "id": "1rM6HlXi6JqU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "idx = random.choice(np.arange(32))\n",
        "plt.imshow(np.squeeze(x_batch[idx, :]))\n",
        "plt.title(f\"Label: {y_batch[idx]}.\")\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "id": "yW3zP6dr6cUK",
        "outputId": "4e77e821-cb09-4015-c90d-a809c2fa2f52"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset class\n",
        "\n",
        "* https://www.tensorflow.org/guide/data\n",
        "* The `from_tensor_slices` method always interprets the first dimension as the number of examples. "
      ],
      "metadata": {
        "id": "-_zOQs6zZZpL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "n = 100\n",
        "x1, x2 = np.arange(n), tf.random.normal((n, 2))\n",
        "y1, y2 = tf.random.normal((n, )), tf.random.normal((n, ))"
      ],
      "metadata": {
        "id": "1lVk_yfWZbq-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_ds = tf.data.Dataset.from_tensor_slices((x1, x2))\n",
        "output_ds = tf.data.Dataset.from_tensor_slices((y1, y2))\n",
        "ds = tf.data.Dataset.zip((input_ds, output_ds))"
      ],
      "metadata": {
        "id": "THU3ftUHazQP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Subsetting"
      ],
      "metadata": {
        "id": "l_Hu0iTdrNpi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "`take(n)` takes the first `n` elements. `skip(n)` takes the elements after the `n`th. "
      ],
      "metadata": {
        "id": "PBu__NiyeeS-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ds_take = ds.take(32)\n",
        "next(iter(ds_take))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iO-bkeI6bEdv",
        "outputId": "9ee315ad-b615-4589-b1eb-a00e240052ca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((<tf.Tensor: shape=(), dtype=int64, numpy=0>,\n",
              "  <tf.Tensor: shape=(2,), dtype=float32, numpy=array([0.47485662, 0.09625979], dtype=float32)>),\n",
              " (<tf.Tensor: shape=(), dtype=float32, numpy=-0.06847728>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=1.8019615>))"
            ]
          },
          "metadata": {},
          "execution_count": 123
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ds_skip = ds.skip(32)\n",
        "next(iter(ds_skip))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l6Mj9stdrbqx",
        "outputId": "3efdac39-1bf1-4ae5-ef60-e72a13bb29f1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((<tf.Tensor: shape=(), dtype=int64, numpy=32>,\n",
              "  <tf.Tensor: shape=(2,), dtype=float32, numpy=array([ 1.0522344 , -0.72098595], dtype=float32)>),\n",
              " (<tf.Tensor: shape=(), dtype=float32, numpy=-0.065669075>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=-0.19583131>))"
            ]
          },
          "metadata": {},
          "execution_count": 124
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### From dictionary"
      ],
      "metadata": {
        "id": "5Fp37V2ahpdn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = {\"x1\": x1, \"x2\": x2, \"y1\": y1, \"y2\": y2}\n",
        "ds = tf.data.Dataset.from_tensor_slices(data)"
      ],
      "metadata": {
        "id": "_LaZZvJ_fH5W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "next(iter(ds))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HFwJh9kyh6KI",
        "outputId": "c46ea79b-bdbc-4ad2-bb19-27e9b719d375"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'x1': <tf.Tensor: shape=(2,), dtype=float32, numpy=array([0.33076918, 0.6156298 ], dtype=float32)>,\n",
              " 'x2': <tf.Tensor: shape=(2,), dtype=float32, numpy=array([-0.24350567,  0.04180278], dtype=float32)>,\n",
              " 'y1': <tf.Tensor: shape=(), dtype=float32, numpy=-0.1680864>,\n",
              " 'y2': <tf.Tensor: shape=(), dtype=float32, numpy=0.9329121>}"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Simple dataset"
      ],
      "metadata": {
        "id": "ySjbwhfGl9sm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "n = 64\n",
        "ds = tf.data.Dataset.from_tensor_slices((np.arange(n), tf.random.normal((n, ))))"
      ],
      "metadata": {
        "id": "gIkkGfK1l-0Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Batching\n",
        "\n",
        "* Note the batch shape is `None` because the number of elements is not necessarily divisble by the batch size. \n",
        "* Add the `drop_remainder` argument to specify the batch size."
      ],
      "metadata": {
        "id": "-BLOTGo7jQhC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ds_batch = ds.batch(32)\n",
        "print(ds_batch.element_spec)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VA4cnlTTbFc1",
        "outputId": "4048edcc-1472-4ed7-a17b-6cde382ee9d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(TensorSpec(shape=(None,), dtype=tf.int64, name=None), TensorSpec(shape=(None,), dtype=tf.float32, name=None))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x, y = next(iter(ds_batch))\n",
        "assert x.shape == (32, )\n",
        "assert y.shape == (32, )"
      ],
      "metadata": {
        "id": "SCIcfyJne0QH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ds_batch = ds.batch(32, drop_remainder=True)\n",
        "print(ds_batch.element_spec)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uKI4gTM4jo70",
        "outputId": "7d4e4c09-cbaa-4c06-d3ad-3b6242f30e7b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(TensorSpec(shape=(32,), dtype=tf.int64, name=None), TensorSpec(shape=(32,), dtype=tf.float32, name=None))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Filtering\n",
        "* Selects which examples to keep in the data set."
      ],
      "metadata": {
        "id": "0xtu6axtlube"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ds_filter = ds.filter(lambda x,y: y > 0)"
      ],
      "metadata": {
        "id": "uGuMqO5dl0qS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "next(iter(ds_filter))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DoRWNGN1mltp",
        "outputId": "7eb16675-1802-41ed-a747-ea4e492259c6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(), dtype=int64, numpy=0>,\n",
              " <tf.Tensor: shape=(), dtype=float32, numpy=1.5304681>)"
            ]
          },
          "metadata": {},
          "execution_count": 98
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Transforming"
      ],
      "metadata": {
        "id": "vDcFZqvfnEOn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def mapping(x, y):\n",
        "  x_float = tf.cast(x, dtype=tf.float32)\n",
        "  return tf.math.exp(x_float), y\n",
        "ds_mapped = ds.map(mapping)"
      ],
      "metadata": {
        "id": "Igt-p2tZnFWP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "next(iter(ds_mapped))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "laLC-vx3nvoX",
        "outputId": "beeaacc9-a476-466e-db76-ac665223cd61"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(), dtype=float32, numpy=1.0>,\n",
              " <tf.Tensor: shape=(), dtype=float32, numpy=1.5304681>)"
            ]
          },
          "metadata": {},
          "execution_count": 105
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Repeat\n",
        "* Allows the dataset to be looped through"
      ],
      "metadata": {
        "id": "XaDOSYrdk-Y0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ds_repeat = ds.batch(32).repeat()"
      ],
      "metadata": {
        "id": "dYPhhDTXlpu5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "iter_ds_repeat = iter(ds_repeat)\n",
        "for i in range(10):\n",
        "  next(iter_ds_repeat)"
      ],
      "metadata": {
        "id": "eO2ZxkPKms-D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Raises an error:\n",
        "# iter_ds = iter(ds.batch(32))\n",
        "# for i in range(10):\n",
        "#   next(iter_ds)"
      ],
      "metadata": {
        "id": "CWU4kFzom4hi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Shuffling\n",
        "\n",
        "* The buffer size (i.e. 128) is the number of examples from which the next batch is randomly selected. "
      ],
      "metadata": {
        "id": "dQW3YvxHkOtT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ds_shuffle = ds.shuffle(128).batch(32)"
      ],
      "metadata": {
        "id": "ylmsN7HskQUa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "next(iter(ds_shuffle))"
      ],
      "metadata": {
        "id": "7tNmLHpokTBG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "645935cf-be91-41a6-f089-ea72ac55e827"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(32,), dtype=int64, numpy=\n",
              " array([33,  8,  5, 38, 35, 34, 30, 32, 22, 41, 49, 12, 51, 28, 42, 48, 15,\n",
              "        56, 13, 37, 31, 55, 25,  6, 36, 19,  7, 24, 29, 23, 59, 43])>,\n",
              " <tf.Tensor: shape=(32,), dtype=float32, numpy=\n",
              " array([ 1.4050804 ,  0.05683026, -1.2787092 ,  0.7690517 , -1.5515121 ,\n",
              "        -0.7789683 ,  0.75681096, -1.21726   , -0.15028606,  0.24728774,\n",
              "        -0.7023052 ,  1.3607677 , -0.00887635,  0.29255393,  0.2068135 ,\n",
              "         1.2381324 , -0.06283021,  1.8825715 , -1.1441343 ,  1.1369661 ,\n",
              "        -2.0497577 ,  0.6452977 , -0.08329682, -0.6064693 ,  0.33989033,\n",
              "         2.3549814 , -0.421403  ,  0.6149732 ,  0.72022015, -1.3319118 ,\n",
              "         2.0669408 ,  0.5729776 ], dtype=float32)>)"
            ]
          },
          "metadata": {},
          "execution_count": 117
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Layers"
      ],
      "metadata": {
        "id": "dq6LVlPQkB0q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Embedding\n",
        "\n",
        "* https://www.tensorflow.org/api_docs/python/tf/keras/layers/Embedding\n",
        "* Consider a sequence $(x_{1}, x_{2}, \\dots, x_{L})$. Each element $x_{l}$ of the sequence is chosen from a finite vocabulary $V$, and may therefore be regarded as a categorical random variable. Using an embedding layer eliminates the need to one-hot encode each $x_{l}$, which is particularly advantageous when $|V|$ is large. \n",
        "* The vocabulary size should be 1 larger than the number of unique tokens.\n",
        "* `mask_zero=True` instructs the embedding layer to ignore zeros.\n",
        "* The Tensorflow Embedding Projection can be used to visualize learned embeddings: https://projector.tensorflow.org/"
      ],
      "metadata": {
        "id": "pCxrWoG1vLI_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size = 101\n",
        "embed_dim = 32\n",
        "embed_layer = tf.keras.layers.Embedding(vocab_size, embed_dim)"
      ],
      "metadata": {
        "id": "qsc-c4nJvMSK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Embed sequences.\n",
        "seqs = tf.constant([[1], [10], [100]])\n",
        "seqs = tf.expand_dims(seqs, axis=-1)\n",
        "h = embed_layer(seqs)\n",
        "print(h.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VFYE4tOv0Lwh",
        "outputId": "c46efe77-85ef-407e-8485-654b7ad1937f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(3, 1, 1, 32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* The token embeddings are accessed via `get_weights`."
      ],
      "metadata": {
        "id": "WL-MofgazuX1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "token_embeddings = embed_layer.get_weights()[0]\n",
        "token_embeddings.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YJnXQMKfztdR",
        "outputId": "3737fb93-4c6e-40f7-ed9d-ca1dc0aa8ea8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(101, 32)"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Extracting Intermediate Layers"
      ],
      "metadata": {
        "id": "ZhptcF0dj83s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input = tf.keras.layers.Input((4, ), name=\"in\")\n",
        "h = tf.keras.layers.Dense(4, activation=\"relu\", name=\"d1\")(input)\n",
        "h = tf.keras.layers.Dense(4, activation=\"relu\", name=\"d2\")(h)\n",
        "output = tf.keras.layers.Dense(1, name=\"out\")(h)\n",
        "model = tf.keras.Model(inputs=input, outputs=output, name=\"full_model\")\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LpFg0KAqhoSu",
        "outputId": "1b21806a-fc13-4350-d0d5-a2113b3412ee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"full_model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " in (InputLayer)             [(None, 4)]               0         \n",
            "                                                                 \n",
            " d1 (Dense)                  (None, 4)                 20        \n",
            "                                                                 \n",
            " d2 (Dense)                  (None, 4)                 20        \n",
            "                                                                 \n",
            " out (Dense)                 (None, 1)                 5         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 45\n",
            "Trainable params: 45\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "extract_penultimate = tf.keras.Model(inputs=model.input, outputs=model.get_layer(\"d2\").output)\n",
        "extract_penultimate.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ewuaRPgfke7A",
        "outputId": "71162508-7afa-43c0-df25-ce63738d5217"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_14\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " in (InputLayer)             [(None, 4)]               0         \n",
            "                                                                 \n",
            " d1 (Dense)                  (None, 4)                 20        \n",
            "                                                                 \n",
            " d2 (Dense)                  (None, 4)                 20        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 40\n",
            "Trainable params: 40\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Freezing\n",
        "\n",
        "* Freezing must take place before compilation."
      ],
      "metadata": {
        "id": "xlwnZk-gmodm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "assert model.get_layer(\"d1\").trainable"
      ],
      "metadata": {
        "id": "6M5zRz7Em8S1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.get_layer(\"d1\").trainable = False\n",
        "assert ~model.get_layer(\"d1\").trainable"
      ],
      "metadata": {
        "id": "aXdb7W5HlF2P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Inspecting layers"
      ],
      "metadata": {
        "id": "4gxhAXYqgHNU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.layers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fIVJcelyh8M1",
        "outputId": "4d1d25de-bfef-41bd-d89f-618c7c983eea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<keras.engine.input_layer.InputLayer at 0x7fe24c900ee0>,\n",
              " <keras.engine.input_layer.InputLayer at 0x7fe24c900e80>,\n",
              " <keras.layers.merging.concatenate.Concatenate at 0x7fe24a6a2f70>,\n",
              " <keras.layers.core.dense.Dense at 0x7fe24c9090a0>,\n",
              " <keras.layers.core.dense.Dense at 0x7fe24c909310>]"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "out1_layer = model.get_layer(\"out1\")\n",
        "out1_layer.weights"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MKQABLnRb9zO",
        "outputId": "cb161ec5-e600-43dd-a318-3214cbd1371e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<tf.Variable 'out1/kernel:0' shape=(2, 1) dtype=float32, numpy=\n",
              " array([[-0.91814005],\n",
              "        [ 1.2598728 ]], dtype=float32)>,\n",
              " <tf.Variable 'out1/bias:0' shape=(1,) dtype=float32, numpy=array([0.00464342], dtype=float32)>]"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "out1_layer.input"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rzH0Gg0lhBHG",
        "outputId": "f3efbb00-e4b2-482c-9489-de5a07cbdd43"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<KerasTensor: shape=(None, 2) dtype=float32 (created by layer 'concatenate_9')>"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "out1_layer.output"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nLNz-XpihlD_",
        "outputId": "c95c62cb-77c7-461a-8a59-2838a7c70028"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<KerasTensor: shape=(None, 1) dtype=float32 (created by layer 'out1')>"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Masking\n",
        "\n",
        "* Padding: https://www.tensorflow.org/api_docs/python/tf/keras/utils/pad_sequences\n",
        "* Masking: https://www.tensorflow.org/api_docs/python/tf/keras/layers/Masking\n"
      ],
      "metadata": {
        "id": "3LZgsolNlBQ0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = [[1], [1, 2], [1, 2, 3]]"
      ],
      "metadata": {
        "id": "ACAwXVd5lIPP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pad_data = tf.keras.utils.pad_sequences(data, padding=\"post\")\n",
        "print(pad_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bRucalBYlPIv",
        "outputId": "f69d0f4f-fa5b-4b79-be2c-0d613f5f12e0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1 0 0]\n",
            " [1 2 0]\n",
            " [1 2 3]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mask_layer = tf.keras.layers.Masking(mask_value=0, name=\"mask\")\n",
        "h = mask_layer(pad_data)"
      ],
      "metadata": {
        "id": "-8s5Uliwls2f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Recurrent\n",
        "\n",
        "* Recurrent layer options include: \n",
        "  - GRU: https://www.tensorflow.org/api_docs/python/tf/keras/layers/GRU\n",
        "  - LSTM: https://www.tensorflow.org/api_docs/python/tf/keras/layers/LSTM\n",
        "  - SimpleRNN: https://www.tensorflow.org/api_docs/python/tf/keras/layers/SimpleRNN\n",
        "* By default, recurrent layers only return the output at the final time-step. Thus, by defult, the output shape of a recurrent layer is `(batch_size, units)`. If `return_sequences=True`, the output shape is `(batch_size, sequence_length, units)`. \n",
        "  - Setting `return_sequences=True` is necessary for stacking recurrent layers.\n",
        "* The Bidirectional layer can wrap a recurrent layer, allowing future time-steps to send information back to earlier time-steps. \n",
        "  - https://www.tensorflow.org/api_docs/python/tf/keras/layers/Bidirectional.\n",
        "  - The output shape of a Bidirectional recurrent layer (assuming `return_sequences=False`) is `(batch_size, 2 * units)`. Notice the number of units is scaled by 2 because the final states of both the forward and backword networks are emitted.\n",
        "* The `statful` argument is used when long sequences are split into a batch of subsequences. When `statful=True`, the internal state of the recurrent layer persists between examples within a batch. "
      ],
      "metadata": {
        "id": "Hu9yC8BG0Cc0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# LSTM example. \n",
        "x = tf.random.normal((10, 16, 1))\n",
        "lstm_layer = tf.keras.layers.LSTM(units=32)\n",
        "h = lstm_layer(x)\n",
        "h.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NbVDOXT90kLb",
        "outputId": "97ae5b9a-24fd-4679-9f8b-6061b9331b8f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([10, 32])"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Stacked LSTM example.\n",
        "lstm1 = tf.keras.layers.LSTM(units=32, return_sequences=True)\n",
        "lstm2 = tf.keras.layers.LSTM(units=16)\n",
        "h = lstm2(lstm1(x))\n",
        "h.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eLzhPrn294NB",
        "outputId": "b26279c1-ad01-4cdc-fc17-6edecf048713"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([10, 16])"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Bidirectional LSTM example.\n",
        "bidir = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(units=8))\n",
        "h = bidir(x)\n",
        "h.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RB7tChiI-I0g",
        "outputId": "248d4feb-0bdd-4c3c-b988-8aaf06b282c0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([10, 16])"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Stateful LSTM.\n",
        "inputs = tf.keras.layers.Input(batch_shape=(10, 16, 1))\n",
        "outputs = tf.keras.layers.LSTM(units=16, stateful=True, name=\"lstm\")(inputs)\n",
        "model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
        "h = model(x)\n",
        "h.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "29uP9Ep5-Tyu",
        "outputId": "1a28aee5-064c-4091-98cc-06fd488cd7e8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([10, 16])"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check states: model.get_layer(\"lstm\").states"
      ],
      "metadata": {
        "id": "WO6eeaCW_jfc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Multiple inputs and outputs"
      ],
      "metadata": {
        "id": "iL1EKHfGYrkH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "n = 100\n",
        "x1 = tf.random.normal((n, ))\n",
        "x2 = tf.random.normal((n, ))\n",
        "y1 = x1 + x2 + tf.random.normal((n, ))\n",
        "y2 = x1 - x2 + tf.random.normal((n, ))"
      ],
      "metadata": {
        "id": "jPqu6jaga2wJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Lists"
      ],
      "metadata": {
        "id": "ZFSgMIHza5st"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input1 = tf.keras.layers.Input(shape=(1, ))\n",
        "input2 = tf.keras.layers.Input(shape=(1, ))\n",
        "h = tf.keras.layers.Concatenate()([input1, input2])\n",
        "output1 = tf.keras.layers.Dense(1)(h)\n",
        "output2 = tf.keras.layers.Dense(1)(h)\n",
        "model = tf.keras.Model(inputs=[input1, input2], outputs=[output1, output2])"
      ],
      "metadata": {
        "id": "5lmY_sqCYrJS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(\n",
        "    loss=[tf.keras.losses.Huber(), tf.keras.losses.MeanSquaredError()],\n",
        "    loss_weights=[0.5, 0.5],\n",
        ")"
      ],
      "metadata": {
        "id": "ZxeECxgwar8X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hisotry = model.fit(x=[x1, x2], y=[y1, y2])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V4Fl0IXYasTR",
        "outputId": "ef9e271f-a8c7-4494-d36b-94276224d664"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4/4 [==============================] - 1s 5ms/step - loss: 3.3374 - dense_loss: 0.8209 - dense_1_loss: 5.8540\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dictionaries"
      ],
      "metadata": {
        "id": "FgWH-M1madoX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input1 = tf.keras.layers.Input(shape=(1, ), name=\"in1\")\n",
        "input2 = tf.keras.layers.Input(shape=(1, ), name=\"in2\")\n",
        "h = tf.keras.layers.Concatenate()([input1, input2])\n",
        "output1 = tf.keras.layers.Dense(1, name=\"out1\")(h)\n",
        "output2 = tf.keras.layers.Dense(1, name=\"out2\")(h)\n",
        "model = tf.keras.Model(inputs=[input1, input2], outputs=[output1, output2])"
      ],
      "metadata": {
        "id": "C0sMGoD6ZiPZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(\n",
        "    loss={\"out1\": tf.keras.losses.Huber(), \"out2\": tf.keras.losses.MeanSquaredError()},\n",
        "    loss_weights=[0.5, 0.5]\n",
        ")"
      ],
      "metadata": {
        "id": "HAtIVn2rbpVp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(\n",
        "    x={\"in1\": x1, \"in2\": x2},\n",
        "    y={\"out1\": y1, \"out2\": y2}\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "goMvVY9sbyPw",
        "outputId": "75baa748-e36e-4c90-86f0-3e4baba8d6d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4/4 [==============================] - 1s 3ms/step - loss: 5.0615 - out1_loss: 1.1954 - out2_loss: 8.9276\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Subclassing"
      ],
      "metadata": {
        "id": "OzL5i_QioZ4d"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Layer\n",
        "\n",
        "* https://www.tensorflow.org/guide/keras/custom_layers_and_models"
      ],
      "metadata": {
        "id": "YKuJBlBVtXTn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class LinearBlock(tf.keras.layers.Layer):\n",
        "\n",
        "  def __init__(self, units, **kwargs):\n",
        "    super(LinearBlock, self).__init__(**kwargs)\n",
        "    self.units = units\n",
        "  \n",
        "  def build(self, input_shape):\n",
        "    # Weight initialization.\n",
        "    self.w = self.add_weight(\n",
        "        shape=(input_shape[-1], self.units), initializer=\"random_normal\")\n",
        "    self.b = self.add_weight(shape=(self.units, ), initializer=\"zeros\")\n",
        "  \n",
        "  def call(self, inputs):\n",
        "    # Layer computation.\n",
        "    return tf.matmul(inputs, self.w) + self.b"
      ],
      "metadata": {
        "id": "IK-qYgqatX-3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "layer = LinearBlock(3)\n",
        "x = tf.ones((2, 4))\n",
        "y = layer(x)\n",
        "y.shape  # Expect: (batch_size, units)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W9fB81RMuKhL",
        "outputId": "b7970928-520b-4494-9d2d-14296f568b67"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([2, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model"
      ],
      "metadata": {
        "id": "Q2y7AUdqtV1X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Classifier(tf.keras.Model):\n",
        "\n",
        "  def __init__(self, classes, **kwargs):\n",
        "    super(Classifier, self).__init__(**kwargs)\n",
        "    # Define layers here.\n",
        "    self.dense = tf.keras.layers.Dense(16, name=\"dense\")\n",
        "    self.drop = tf.keras.layers.Dropout(rate=0.5, name=\"drop\")\n",
        "    self.out = tf.keras.layers.Dense(classes, activation=\"softmax\", name=\"out\")\n",
        "  \n",
        "  def call(self, inputs, training=False):\n",
        "    # Define forward pass here.\n",
        "    h = self.dense(inputs)\n",
        "    h = self.drop(h, training=training)\n",
        "    return self.out(h)\n"
      ],
      "metadata": {
        "id": "N_eCILF0oazT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Classifier(classes=2, name=\"classifier\")\n",
        "model.build(input_shape=(32, 4))\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ufksIlQEqSzo",
        "outputId": "9e96d251-8b97-4ee4-eac6-4574960fff34"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"classifier\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               multiple                  80        \n",
            "                                                                 \n",
            " drop (Dropout)              multiple                  0         \n",
            "                                                                 \n",
            " out (Dense)                 multiple                  34        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 114\n",
            "Trainable params: 114\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Differentiation"
      ],
      "metadata": {
        "id": "0BbON1S3f8ok"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pjzTlS_e-3ij"
      },
      "outputs": [],
      "source": [
        "x = tf.Variable(1., dtype=tf.float32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X-I68KMU-_Wn"
      },
      "outputs": [],
      "source": [
        "with tf.GradientTape(persistent=True) as tape:\n",
        "  y = x ** 2 + x + 1\n",
        "  z = tf.math.sin(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "beK-3f8C_Hev",
        "outputId": "1b3f7965-1548-4131-807e-f8126b10c462"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(3.0, shape=(), dtype=float32)\n"
          ]
        }
      ],
      "source": [
        "g = tape.gradient(y, x)\n",
        "print(g)\n",
        "assert tf.is_tensor(g)\n",
        "assert g.numpy() == 2 * 1.0 + 1.0"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "g = tape.gradient(z, x)\n",
        "print(g)\n",
        "assert np.isclose(g.numpy(), np.cos(1.0))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nt2KktNkeK_s",
        "outputId": "e0c9008e-0d6b-4970-f0fb-c4a3fea857dc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(0.5403023, shape=(), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Custom Training\n",
        "\n",
        "* https://www.tensorflow.org/tutorials/customization/custom_training_walkthrough#training_loop"
      ],
      "metadata": {
        "id": "8kFsO574lOGv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "n = 100\n",
        "x = tf.random.normal((n, ))\n",
        "e = tf.random.normal((n, ))\n",
        "y = 2 * tf.ones((n, )) + 2 * x + e"
      ],
      "metadata": {
        "id": "nFQ2T6JRlPdd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = tf.keras.layers.Input((1,))\n",
        "outputs = tf.keras.layers.Dense(1)(inputs)\n",
        "model = tf.keras.Model(inputs=inputs, outputs=outputs)"
      ],
      "metadata": {
        "id": "EKdKYOR9laS0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Loss.\n",
        "@tf.function \n",
        "def huber_loss(yhat, y):\n",
        "  yhat = tf.squeeze(yhat)\n",
        "  abs_delta = tf.abs(tf.subtract(yhat, y))\n",
        "  huber = tf.where(\n",
        "      abs_delta < 1, 0.5 * tf.square(abs_delta), 0.5 * (abs_delta - 0.5))\n",
        "  return tf.reduce_sum(huber)\n",
        "\n",
        "# Optimizer.\n",
        "optim = tf.keras.optimizers.Adam(learning_rate=0.01)"
      ],
      "metadata": {
        "id": "nskVLYG8lzq3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "last_epoch_loss = np.inf\n",
        "\n",
        "for epoch in range(1000):\n",
        "\n",
        "  # Calculate gradients.\n",
        "  with tf.GradientTape() as tape:\n",
        "    yhat = model(x)\n",
        "    loss = huber_loss(yhat, y)\n",
        "    grad = tape.gradient(loss, model.trainable_variables)\n",
        "  \n",
        "  # Update.\n",
        "  optim.apply_gradients(zip(grad, model.trainable_variables))\n",
        "\n",
        "  # Report.\n",
        "  if epoch == 1:\n",
        "    delta = loss\n",
        "  else:\n",
        "    delta = 0.9 * delta + 0.1 * np.abs(last_epoch_loss - loss)\n",
        "  if epoch % 100 == 0:\n",
        "    print(f\"Epoch: {epoch}, Loss: {loss:.3f}, Delta: {delta:.3f}\")\n",
        "  \n",
        "  # Break condition.\n",
        "  if delta < 1e-3:\n",
        "    break\n",
        "  last_epoch_loss = loss"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4O7qQr5KmUT2",
        "outputId": "a9e452ca-8b28-48e3-e356-e30d58152cfe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0, Loss: 125.018, Delta: inf\n",
            "Epoch: 100, Loss: 77.397, Delta: 0.437\n",
            "Epoch: 200, Loss: 38.242, Delta: 0.275\n",
            "Epoch: 300, Loss: 28.811, Delta: 0.067\n",
            "Epoch: 400, Loss: 28.168, Delta: 0.009\n",
            "Epoch: 500, Loss: 27.854, Delta: 0.001\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Example with batching"
      ],
      "metadata": {
        "id": "XeRCBTcBw6sw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Dense(10, activation=\"tanh\"),\n",
        "    tf.keras.layers.Dense(1, activation=\"linear\")\n",
        "])"
      ],
      "metadata": {
        "id": "i8895sccxroB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n = 1000\n",
        "x = tf.random.normal((n, 1))\n",
        "e = tf.random.normal((n, ))\n",
        "y = 2 * tf.ones((n, )) + 2 * tf.math.sin(x * (1 - x)) + e"
      ],
      "metadata": {
        "id": "-Gulm_-4w9WU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ds = tf.data.Dataset.from_tensor_slices((x, y))\n",
        "ds_batch = ds.batch(32)"
      ],
      "metadata": {
        "id": "Q2JX54gExAzt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mse_loss = tf.keras.losses.MeanSquaredError()\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)"
      ],
      "metadata": {
        "id": "WuyWyUxexKYW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epoch_losses = []\n",
        "epoch_maes = []\n",
        "last_epoch_loss = np.inf\n",
        "\n",
        "for epoch in range(100):\n",
        "\n",
        "  epoch_loss = tf.keras.metrics.Mean()\n",
        "  epoch_mae = tf.keras.metrics.MeanAbsoluteError()\n",
        "\n",
        "  # Loop over batches.\n",
        "  for x, y in ds_batch:\n",
        "\n",
        "    # Gradient. \n",
        "    with tf.GradientTape() as tape:\n",
        "      yhat = model(x)\n",
        "      loss = mse_loss(yhat, y)\n",
        "      grad = tape.gradient(loss, model.trainable_variables)\n",
        "    \n",
        "    # Update.\n",
        "    optim.apply_gradients(zip(grad, model.trainable_variables))\n",
        "    epoch_loss(loss)\n",
        "    epoch_mae(yhat, y)\n",
        "  \n",
        "  # Epoch results.\n",
        "  epoch_loss = epoch_loss.result().numpy()\n",
        "  epoch_mae = epoch_mae.result().numpy()\n",
        "  epoch_losses.append(epoch_loss)\n",
        "  epoch_maes.append(epoch_mae)\n",
        "\n",
        "  # Report.\n",
        "  if epoch % 10 == 0:\n",
        "    print(f\"Epoch: {epoch}, Loss: {epoch_loss:.3f}, MAE: {epoch_mae:.3f}\")\n",
        "  \n",
        "  # Break condition.\n",
        "  delta = last_epoch_loss - epoch_loss\n",
        "  if delta < 1e-3:\n",
        "    break\n",
        "  last_epoch_loss = epoch_loss\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "38IJCdTzxYU2",
        "outputId": "1060910d-01c2-4068-97cc-85d3caa6a676"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0, Loss: 2.064, MAE: 1.129\n",
            "Epoch: 10, Loss: 1.315, MAE: 0.892\n",
            "Epoch: 20, Loss: 1.242, MAE: 0.870\n",
            "Epoch: 30, Loss: 1.205, MAE: 0.859\n",
            "Epoch: 40, Loss: 1.182, MAE: 0.852\n",
            "Epoch: 50, Loss: 1.164, MAE: 0.846\n",
            "Epoch: 60, Loss: 1.149, MAE: 0.841\n",
            "Epoch: 70, Loss: 1.137, MAE: 0.836\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tokenization\n",
        "\n",
        "* Tokenization refers to replacing words with numeric *tokens* representing (e.g.) the frequency of those words in some document or corpus.\n",
        "* https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/text/Tokenizer"
      ],
      "metadata": {
        "id": "FgLIzLZ3sT9i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = [\n",
        "    \"The first sentence.\",\n",
        "    \"The second sentence.\",\n",
        "    \"The third sentence.\"\n",
        "]\n",
        "\n",
        "new_data = {\n",
        "    \"The fourth sentence.\"\n",
        "}"
      ],
      "metadata": {
        "id": "HIjjBHjlsU4U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# OOV = Out of Vocabulary\n",
        "tokenizer = tf.keras.preprocessing.text.Tokenizer(oov_token=\"UNK\")"
      ],
      "metadata": {
        "id": "fRelaOqhs8HD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Learn word frequencies.\n",
        "tokenizer.fit_on_texts(train_data)"
      ],
      "metadata": {
        "id": "a9fsDMJctera"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "config = tokenizer.get_config()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BLCEPLGTtiYA",
        "outputId": "3d3d5d35-8e4b-4bb9-decb-f857a55d766a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"1\": \"UNK\", \"2\": \"the\", \"3\": \"sentence\", \"4\": \"first\", \"5\": \"second\", \"6\": \"third\"}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Word counts.\n",
        "config[\"word_counts\"]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "jo6MukMDuh3s",
        "outputId": "051c3dbd-4085-4dc8-a9bc-cd32eb4e8b45"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'{\"the\": 6, \"first\": 2, \"sentence\": 6, \"second\": 2, \"third\": 2}'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Index to word mapping.\n",
        "index_to_word = config[\"index_word\"]\n",
        "print(index_to_word)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c7ONB5JauczL",
        "outputId": "ca89bd98-2260-474b-aebf-d721a39a8022"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"1\": \"UNK\", \"2\": \"the\", \"3\": \"sentence\", \"4\": \"first\", \"5\": \"second\", \"6\": \"third\"}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Word to index mapping.\n",
        "word_to_index = config[\"word_index\"]\n",
        "print(word_to_index)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WzXUIdUAtrHX",
        "outputId": "b441eeb2-4fc8-421b-e58b-ba959640ce3e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"UNK\": 1, \"the\": 2, \"sentence\": 3, \"first\": 4, \"second\": 5, \"third\": 6}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Map text to sequence.\n",
        "new_data_seq = tokenizer.texts_to_sequences(new_data)\n",
        "print(new_data_seq)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "votdW7GouO4J",
        "outputId": "3c7d6880-7a40-4872-8872-651aedd6de29"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[2, 1, 3]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Map sequence to text.\n",
        "new_data_recovered = tokenizer.sequences_to_texts(new_data_seq)\n",
        "print(new_data_recovered)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gqxhhT0_u0bq",
        "outputId": "6ce9b048-11b1-4a7e-a89e-908b6b42f737"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['the UNK sentence']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tJj7JjnxvIc9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}