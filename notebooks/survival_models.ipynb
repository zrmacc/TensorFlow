{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 417,
      "metadata": {
        "id": "hIBg7AfF6Mnx"
      },
      "outputs": [],
      "source": [
        "from typing import Any, Dict, Iterable, Tuple\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Generate data"
      ],
      "metadata": {
        "id": "WuL4E2KA6XSs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "N_COVAR = 128"
      ],
      "metadata": {
        "id": "TGTspMD3dys9"
      },
      "execution_count": 418,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def gen_data(\n",
        "  n: int,\n",
        "  base_rate=0.50,\n",
        "  cens_prop=0.20,\n",
        "  n_covar=N_COVAR,\n",
        ") -> Dict[str, np.ndarray]:\n",
        "  \"\"\"Generate data.\n",
        "  \n",
        "  Args:\n",
        "    n: Sample size.\n",
        "    base_rate: Base event rate.\n",
        "    cens_prop: Expected censoring proportion.\n",
        "    n_covar: Number of covariates.\n",
        "    n_freq: Number of frequencies.\n",
        "  \n",
        "  \"\"\"\n",
        "\n",
        "  # Covariates.\n",
        "  x = np.random.rand(n, n_covar)\n",
        "  \n",
        "  # Linear predictor.\n",
        "  coef = np.random.randn(n_covar)\n",
        "  eta = np.dot(x, coef)\n",
        "  eta = (eta - np.mean(eta)) / np.std(eta)\n",
        "\n",
        "  # Time-to-event.\n",
        "  event_rate = base_rate * np.exp(eta)\n",
        "  event_time = np.random.exponential(scale=1/event_rate, size=len(event_rate))\n",
        "\n",
        "  cens_rate = cens_prop / (1 - cens_prop) * event_rate \n",
        "  cens_time = np.random.exponential(scale=1/cens_rate, size=len(cens_rate))\n",
        "\n",
        "  status = (event_time <= cens_time)\n",
        "  time = np.where(status, event_time, cens_time)\n",
        "\n",
        "  # Target matrix.\n",
        "  y = np.stack((status, time), axis=1)\n",
        "\n",
        "  # Output.\n",
        "  return {\n",
        "    \"x\": x,\n",
        "    \"risk\": event_rate,\n",
        "    \"status\": status,\n",
        "    \"time\": time,\n",
        "    \"y\": y,\n",
        "  }"
      ],
      "metadata": {
        "id": "0nGaPZhy6RHQ"
      },
      "execution_count": 419,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def split_data(\n",
        "  data: Dict[str, np.ndarray],\n",
        "  train_prop: float = 0.6,\n",
        "  val_prop: float = 0.2,\n",
        ") -> Dict[str, np.ndarray]:\n",
        "\n",
        "  n = len(data[\"time\"])\n",
        "  test_prop = 1 - (train_prop + val_prop)\n",
        "  assert test_prop >= 0\n",
        "\n",
        "  n_train = int(n * train_prop)\n",
        "  n_val = int(n * val_prop)\n",
        "  n_test = int(n * test_prop)\n",
        "\n",
        "  out = {}\n",
        "  for key in data.keys():\n",
        "    out[f\"train_{key}\"] = data[key][:n_train]\n",
        "    out[f\"val_{key}\"] = data[key][n_train:(n_train + n_val)]\n",
        "    out[f\"test_{key}\"] = data[key][(n_train + n_val):]\n",
        "  \n",
        "  return out"
      ],
      "metadata": {
        "id": "WiBMyLRfA9Hw"
      },
      "execution_count": 420,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Overall"
      ],
      "metadata": {
        "id": "xSG1hyTxfldO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class PrepData:\n",
        "\n",
        "  def __init__(\n",
        "    self,\n",
        "    n: int,\n",
        "    base_rate=0.50,\n",
        "    batch_size=128,\n",
        "    cens_prop=0.20,\n",
        "    n_covar=N_COVAR,\n",
        "    train_prop=0.6,\n",
        "    val_prop=0.2,\n",
        "  ) -> None:\n",
        "    self.data = gen_data(n, base_rate, cens_prop, n_covar)\n",
        "    self.split_data = split_data(self.data, train_prop, val_prop)\n",
        "    self.n = n\n",
        "    self.base_rate = base_rate\n",
        "    self.cens_prop = cens_prop\n",
        "    self.n_covar = n_covar\n",
        "  \n",
        "  def get_orig_data(self) -> Dict[str, np.ndarray]:\n",
        "    return self.data\n",
        "  \n",
        "  def get_split_data(self) -> Dict[str, np.ndarray]:\n",
        "    return self.split_data"
      ],
      "metadata": {
        "id": "yE97Bl7wgxr-"
      },
      "execution_count": 424,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DataGenerator:\n",
        "\n",
        "  def __init__(\n",
        "    self,\n",
        "    x: np.ndarray,\n",
        "    y: np.ndarray,\n",
        "    batch_size=128,\n",
        "  ):\n",
        "    self.n = x.shape[0]\n",
        "    self.x = x\n",
        "    self.y = y  \n",
        "    self.batch_size = batch_size\n",
        "    self.n_covar = x.shape[1]\n",
        "    self.steps_per_epoch = self.n // batch_size\n",
        "   \n",
        "  def get_batch(\n",
        "      self, index: np.ndarray) -> Tuple[np.ndarray, Tuple[np.ndarray]]:\n",
        "      x = self.x[index]\n",
        "      y = self.y[index]\n",
        "      return x, y\n",
        "  \n",
        "  def generator(self) -> Iterable[Tuple[np.ndarray, Tuple[np.ndarray]]]:\n",
        "    index = np.arange(self.n)\n",
        "    for b in range(self.steps_per_epoch):\n",
        "      start = b * self.batch_size\n",
        "      idx = index[start:(start + self.batch_size)]\n",
        "      yield self.get_batch(idx)\n",
        "  \n",
        "  def make_dataset(self) -> tf.data.Dataset:\n",
        "    \"\"\"Create dataset from generator.\"\"\"\n",
        "    ds = tf.data.Dataset.from_generator(\n",
        "      self.generator,\n",
        "      output_signature=(\n",
        "        tf.TensorSpec(shape=(self.batch_size, self.n_covar), dtype=tf.float32),\n",
        "        tf.TensorSpec(shape=(self.batch_size, 2), dtype=tf.float32)\n",
        "      )\n",
        "    )\n",
        "    return ds\n",
        "  \n",
        "  def __call__(self) -> tf.data.Dataset:\n",
        "    return self.make_dataset()"
      ],
      "metadata": {
        "id": "9hoeDEeEBSYP"
      },
      "execution_count": 425,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def prep_datasets(\n",
        "    split_data: Dict[str, np.ndarray],\n",
        "    batch_size=128,\n",
        "  ) -> Dict[str, tf.data.Dataset]:\n",
        "  sets = [\"train\", \"val\", \"test\"]\n",
        "  out = {}\n",
        "  for key in sets:\n",
        "    x = split_data[f\"{key}_x\"]\n",
        "    y = split_data[f\"{key}_y\"]\n",
        "    data_fn = DataGenerator(x, y, batch_size)\n",
        "    ds = data_fn()\n",
        "    out[f\"{key}\"] = ds\n",
        "  return out"
      ],
      "metadata": {
        "id": "ao4KzS4fcGRu"
      },
      "execution_count": 448,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Kaplan-Meier"
      ],
      "metadata": {
        "id": "6zIn6NnUz8-_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Build masks"
      ],
      "metadata": {
        "id": "TJDJSJRB3xHw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def build_masks(status: np.ndarray, time: np.ndarray) -> Tuple[np.ndarray]:\n",
        "  \"\"\"Build masks.\n",
        "\n",
        "  Create unique-time (row) by subject (col) boolean masks.\n",
        "\n",
        "  Returns:\n",
        "    at_risk: [t, i] = True if subject i is at risk at time t.\n",
        "    cens: [t, i] = True if subject is is censored at time t.\n",
        "    event: [t, i] = True if subject i has an event at time t.\n",
        "    unique_times: Unique times corresponding to the rows.\n",
        "\n",
        "  \"\"\"\n",
        "  n_subj = len(time)\n",
        "\n",
        "  # Add 0 if not present.\n",
        "  unique_times = np.sort(np.unique(time))\n",
        "  if not (0 in unique_times):\n",
        "    unique_times = np.insert(unique_times, 0, 0)\n",
        "  n_unique_time = len(unique_times)\n",
        "\n",
        "  # Masks.\n",
        "  at_risk = np.zeros(shape=(n_unique_time, n_subj), dtype=bool)\n",
        "  cens = np.zeros(shape=(n_unique_time, n_subj), dtype=bool)\n",
        "  event = np.zeros(shape=(n_unique_time, n_subj), dtype=bool)\n",
        "\n",
        "  for i in range(n_subj):\n",
        "    at_risk[:, i] = (time[i] >= unique_times)\n",
        "    which_time = (unique_times == time[i])\n",
        "    cens[:, i] = (not status[i]) * which_time\n",
        "    event[:, i] = status[i] * which_time\n",
        "\n",
        "  return at_risk, cens, event, unique_times"
      ],
      "metadata": {
        "id": "16IWJQfX0zBM"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n = 5\n",
        "status = np.array(np.round(np.random.rand(n)), dtype=bool)\n",
        "time = np.arange(n, dtype=float)"
      ],
      "metadata": {
        "id": "lir0LH0b1QL9"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Status:\")\n",
        "print(status)\n",
        "print(\"\\n\")\n",
        "print(\"Time:\")\n",
        "print(time)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "orADikygX2Pm",
        "outputId": "743ce2fb-2774-4208-b2d7-41f2305eeb2c"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Status:\n",
            "[ True  True  True False  True]\n",
            "\n",
            "\n",
            "Time:\n",
            "[0. 1. 2. 3. 4.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "at_risk, cens, event, unique_times = build_masks(status, time)"
      ],
      "metadata": {
        "id": "QaEygEatW8hV"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"At risk:\")\n",
        "print(at_risk)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "elK650DUXprE",
        "outputId": "42677b4b-f316-4687-f2a7-8d4f6ab28d69"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "At risk:\n",
            "[[ True  True  True  True  True]\n",
            " [False  True  True  True  True]\n",
            " [False False  True  True  True]\n",
            " [False False False  True  True]\n",
            " [False False False False  True]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Censored:\")\n",
        "print(cens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QP-ed6w_YBxO",
        "outputId": "3ce2d6b3-2182-498a-b128-11d83035076e"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Censored:\n",
            "[[False False False False False]\n",
            " [False False False False False]\n",
            " [False False False False False]\n",
            " [False False False  True False]\n",
            " [False False False False False]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Event:\")\n",
        "print(event)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MJ13ZeW7ZTpp",
        "outputId": "403b9c2e-a0f6-4cfe-b2ee-10ef4fc4aa4c"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Event:\n",
            "[[ True False False False False]\n",
            " [False  True False False False]\n",
            " [False False  True False False]\n",
            " [False False False False False]\n",
            " [False False False False  True]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tabulate KM"
      ],
      "metadata": {
        "id": "CQv-_vxR5iEm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def tab_km(status: np.ndarray, time: np.ndarray) -> pd.DataFrame:\n",
        "  \"\"\"Taublate Kaplan-Meier.\"\"\"\n",
        "  at_risk, cens, event, unique_times = build_masks(status, time)\n",
        "\n",
        "  out = pd.DataFrame({\n",
        "    \"time\": unique_times,\n",
        "    \"n_at_risk\": np.sum(at_risk, axis=1),\n",
        "    \"n_event\": np.sum(event, axis=1),\n",
        "    \"n_cens\": np.sum(cens, axis=1),\n",
        "  })\n",
        "  out[\"haz\"] = out.n_event / out.n_at_risk\n",
        "  out[\"surv\"] = np.cumprod(1 - out.haz)\n",
        "  return out  "
      ],
      "metadata": {
        "id": "3MvKcTRA5j7Y"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Estimator"
      ],
      "metadata": {
        "id": "Uc88st1q3zKf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class KaplanMeier:\n",
        "\n",
        "  def __init__(self, status: np.ndarray, time: np.ndarray) -> None:\n",
        "    self.status = status\n",
        "    self.time = time\n",
        "    self.km = tab_km(self.status, self.time)\n",
        "  \n",
        "  def return_table(self) -> pd.DataFrame:\n",
        "    return self.km\n",
        "    \n",
        "  def __call__(self, x: float) -> float:\n",
        "    km = self.km\n",
        "    return km.surv[np.max(np.where(km.time <= x))]"
      ],
      "metadata": {
        "id": "bp-kQa8Qz_Q1"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit Kaplan-Meier.\n",
        "km = KaplanMeier(\n",
        "  status = np.array([True, False, True, False]),\n",
        "  time = np.arange(1, 5)\n",
        ")\n",
        "km.return_table()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "orUVzFo7_eQM",
        "outputId": "679034e3-2d74-4bba-f11e-f42a55dc4b64"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   time  n_at_risk  n_event  n_cens   haz   surv\n",
              "0     0          4        0       0  0.00  1.000\n",
              "1     1          4        1       0  0.25  0.750\n",
              "2     2          3        0       1  0.00  0.750\n",
              "3     3          2        1       0  0.50  0.375\n",
              "4     4          1        0       1  0.00  0.375"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-499c047b-6549-457d-8bbf-ba4b729e28f2\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>time</th>\n",
              "      <th>n_at_risk</th>\n",
              "      <th>n_event</th>\n",
              "      <th>n_cens</th>\n",
              "      <th>haz</th>\n",
              "      <th>surv</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.750</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.750</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.375</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.375</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-499c047b-6549-457d-8bbf-ba4b729e28f2')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-499c047b-6549-457d-8bbf-ba4b729e28f2 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-499c047b-6549-457d-8bbf-ba4b729e28f2');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate Kaplan-Meier.\n",
        "km(1.1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jwIEwT3I_lt4",
        "outputId": "52a60374-e964-435f-8d97-866780b71db7"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.75"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# C-statistic\n",
        "\n",
        "* Reference: [On the C-statistics for Evaluating Overall Adequacy of Risk Prediction Procedures with Censored Survival Data](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3079915/)."
      ],
      "metadata": {
        "id": "yKf4ZGBFBlFY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Concord:\n",
        "  \"\"\"Calculate concordance.\n",
        "  \n",
        "  Note that the Kaplan-Meier curve of the censoring distribution may be fit\n",
        "  using different data from that used to calculate the C-statistic.\n",
        "  \n",
        "  \"\"\"\n",
        "\n",
        "  def __init__(self, status: np.ndarray, time: np.ndarray) -> None:\n",
        "    self.km = KaplanMeier(~status, time)\n",
        "  \n",
        "  def __call__(\n",
        "    self,\n",
        "    risk: np.ndarray,\n",
        "    status: np.ndarray,\n",
        "    time: np.ndarray,\n",
        "    tau=None\n",
        "  ) -> float:\n",
        "\n",
        "    n = len(risk)\n",
        "    upper = 0\n",
        "    lower = 0\n",
        "\n",
        "    if not tau:\n",
        "      tau = np.max(time)\n",
        "\n",
        "    for i in range(n):\n",
        "      di, ti, ri = status[i], time[i], risk[i]\n",
        "\n",
        "      # Only cases contribute.\n",
        "      if not di:\n",
        "        continue\n",
        "\n",
        "      for j in range(n):\n",
        "        tj, rj = time[j], risk[j]\n",
        "        denom = di * (ti < tj) * (ti < tau)\n",
        "\n",
        "        # Only calculate censoring weights if denom is non-zero.\n",
        "        if denom:\n",
        "          p_cens = np.squeeze(self.km(ti))\n",
        "          weight = 1 / (p_cens ** 2)\n",
        "          upper += denom * weight * (ri > rj)\n",
        "          lower += denom * weight\n",
        "\n",
        "    return upper / lower if lower > 0 else 0.5"
      ],
      "metadata": {
        "id": "HqdSaYhFBmmQ"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Proportional hazards loss"
      ],
      "metadata": {
        "id": "cZID5Jn5DH1l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CoxLoss(tf.keras.losses.Loss):\n",
        "\n",
        "  def __init__(self, **kwargs):\n",
        "    super().__init__(**kwargs) \n",
        "  \n",
        "  def call(\n",
        "      self,\n",
        "      y_true: Tuple[tf.Tensor],\n",
        "      y_pred: tf.Tensor\n",
        "  ) -> tf.Tensor:\n",
        "    \"\"\"Calculate Cox PH Loss.\n",
        "    \n",
        "    Args:\n",
        "      y_true: (status, time).\n",
        "      y_pred: risk.\n",
        "\n",
        "    \"\"\"\n",
        "    \n",
        "    # Note: autograph requires unpacking using indices.\n",
        "    status = tf.cast(y_true[:, 0], dtype=bool)\n",
        "    time = tf.cast(y_true[:, 1], dtype=tf.float32)\n",
        "    y_pred = tf.cast(y_pred, tf.float32)\n",
        "    # assert status.shape == time.shape\n",
        "    \n",
        "    # Matrix where `at_risk[i, j] = True` if subject j is at risk\n",
        "    # at the event time for subject i. \n",
        "    at_risk = tf.map_fn(\n",
        "      lambda x: (time >= x), time, fn_output_signature=bool)\n",
        "    \n",
        "    risk_score = tf.squeeze(y_pred)\n",
        "    risk_score_mat = tf.math.multiply(\n",
        "        tf.ones((time.shape[0], time.shape[0]), dtype=tf.float32), risk_score)\n",
        "    \n",
        "    # Only at-risk subjects contribute to the denominator.\n",
        "    # Note: logsumexp is implemented manually because tf.reduce_logsumexp\n",
        "    # gives an error when used with graph execution.\n",
        "    max_score = tf.reduce_max(risk_score)\n",
        "    risk_score_mat = tf.subtract(risk_score_mat, max_score)\n",
        "    risk_sets = tf.ragged.boolean_mask(risk_score_mat, at_risk)\n",
        "    \n",
        "    set_exp = tf.math.exp(risk_sets)\n",
        "    set_sum = tf.reduce_sum(set_exp, axis=1)\n",
        "    denom = tf.add(tf.math.log(set_sum), max_score)\n",
        "\n",
        "    # The log-likelihood only increments at event times.\n",
        "    diff = tf.subtract(risk_score, denom)\n",
        "    return -1 * tf.reduce_mean(tf.ragged.boolean_mask(diff, status))\n"
      ],
      "metadata": {
        "id": "HyD6ZqDxXqji"
      },
      "execution_count": 367,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Testing"
      ],
      "metadata": {
        "id": "Obg6A_Lwiu4Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def logsumexp(x: np.ndarray) -> np.ndarray:\n",
        "  delta = np.max(x)\n",
        "  y = x - delta\n",
        "  return delta + np.log(np.sum(np.exp(y)))"
      ],
      "metadata": {
        "id": "z7iWpxnvlfyn"
      },
      "execution_count": 252,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if False:\n",
        "  time = tf.constant(np.array([1, 2, 3]), dtype=tf.float32)\n",
        "  status = tf.constant(np.array([True, False, True]), dtype=bool)\n",
        "  risk_score = tf.constant(np.array([3, 2, 1]), dtype=tf.float32)\n",
        "  at_risk = tf.map_fn(lambda x: (time >= x), time, dtype=bool)\n",
        "\n",
        "  # Denominator calculation.\n",
        "  risk_score_mat = tf.math.multiply(\n",
        "      tf.ones_like(at_risk, dtype=risk_score.dtype), risk_score)\n",
        "  denom = tf.reduce_logsumexp(\n",
        "      tf.ragged.boolean_mask(risk_score_mat, at_risk), axis=1)\n",
        "\n",
        "  exp_denom = np.array([\n",
        "      logsumexp([3., 2., 1.]),\n",
        "      logsumexp([2., 1.]),\n",
        "      logsumexp([1.])\n",
        "  ])\n",
        "  assert np.allclose(denom.numpy(), exp_denom)\n",
        "\n",
        "  # Overall calculation.\n",
        "  y_true = (status, time)\n",
        "  y_pred = risk_score\n",
        "  loss_fn = CoxLoss()\n",
        "  obs = loss_fn(y_true, y_pred)\n",
        "  exp = -1 * np.sum(\n",
        "      status.numpy() * (risk_score.numpy() - exp_denom)) / np.sum(status.numpy())\n",
        "  assert np.allclose(obs, exp)"
      ],
      "metadata": {
        "id": "GQ8C8Eh4sQ1u"
      },
      "execution_count": 253,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Modeling"
      ],
      "metadata": {
        "id": "Z1LMP4cm-H2n"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model architecture"
      ],
      "metadata": {
        "id": "ZyGO8Ily-Nve"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def linear_model() -> tf.keras.Model:\n",
        "  input = tf.keras.layers.Input(shape=(N_COVAR,), name=\"input\", dtype=tf.float32)\n",
        "  output = tf.keras.layers.Dense(1, name=\"output\")(input)\n",
        "  model = tf.keras.Model(input, output, name=\"model\")\n",
        "  return model"
      ],
      "metadata": {
        "id": "7KFYSWDHoL9j"
      },
      "execution_count": 433,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def dropout_model() -> tf.keras.Model:\n",
        "  input = tf.keras.layers.Input(shape=(N_COVAR,), name=\"input\")\n",
        "  h = tf.keras.layers.Dense(\n",
        "    32,\n",
        "    activation=\"relu\",\n",
        "    kernel_regularizer=tf.keras.regularizers.L2(),\n",
        "    name=\"dense1\"\n",
        "  )(input)\n",
        "  h = tf.keras.layers.Dropout(0.50, name=\"drop\")(h)\n",
        "  h = tf.keras.layers.Dense(\n",
        "    32,\n",
        "    activation=\"relu\",\n",
        "    kernel_regularizer=tf.keras.regularizers.L2(),\n",
        "    name=\"dense2\"\n",
        "  )(h)\n",
        "  output = tf.keras.layers.Dense(1, name=\"output\")(h)\n",
        "  model = tf.keras.Model(input, output, name=\"model\")\n",
        "  return model"
      ],
      "metadata": {
        "id": "szLhusBhz1gH"
      },
      "execution_count": 434,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data sets"
      ],
      "metadata": {
        "id": "AFcoK7inj6qe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_fn = PrepData(n=128 * 10)"
      ],
      "metadata": {
        "id": "dtG8B39gcV5n"
      },
      "execution_count": 435,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Built-in training"
      ],
      "metadata": {
        "id": "FUg6Zmqxzpca"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### From tensors"
      ],
      "metadata": {
        "id": "ojpsSVEH5YFi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Model.\n",
        "model = linear_model()"
      ],
      "metadata": {
        "id": "duPYjEi0rxxF"
      },
      "execution_count": 436,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(\n",
        "  optimizer=tf.keras.optimizers.Adam(),\n",
        "  loss=CoxLoss()\n",
        ")"
      ],
      "metadata": {
        "id": "ISkkdGmY0oJx"
      },
      "execution_count": 437,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = data_fn.get_orig_data()\n",
        "x = tf.constant(data[\"x\"], dtype=tf.float32)\n",
        "y = tf.constant(data[\"y\"], dtype=tf.float32)"
      ],
      "metadata": {
        "id": "-IkRxa2epVyd"
      },
      "execution_count": 438,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(\n",
        "  x=x,\n",
        "  y=y,\n",
        "  epochs=2,\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G0HNR-Eg0wc3",
        "outputId": "1d387210-9538-4a8c-eae4-bf1546f3e603"
      },
      "execution_count": 439,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/2\n",
            "40/40 [==============================] - 1s 2ms/step - loss: 2.5714\n",
            "Epoch 2/2\n",
            "40/40 [==============================] - 0s 2ms/step - loss: 2.5457\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### From datasets"
      ],
      "metadata": {
        "id": "6WDmZH2C5j2z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Model.\n",
        "model = linear_model()"
      ],
      "metadata": {
        "id": "4zcKBn1r55RU"
      },
      "execution_count": 440,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(\n",
        "  optimizer=tf.keras.optimizers.Adam(),\n",
        "  loss=CoxLoss()\n",
        ")"
      ],
      "metadata": {
        "id": "nLnz4AJW5x4V"
      },
      "execution_count": 441,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_generator = DataGenerator(data[\"x\"], data[\"y\"])\n",
        "ds = data_generator()"
      ],
      "metadata": {
        "id": "TVvJ2TceCa1B"
      },
      "execution_count": 442,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training dataset.\n",
        "history = model.fit(\n",
        "  x=ds,\n",
        "  epochs=2,\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "14H8mjPq5O4o",
        "outputId": "319d385c-fcfd-4485-9887-a9376c4d57e2"
      },
      "execution_count": 443,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/2\n",
            "10/10 [==============================] - 1s 7ms/step - loss: 3.9035\n",
            "Epoch 2/2\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 3.8898\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Training and validation datasets.\n",
        "ds = prep_datasets(data_fn.get_split_data())"
      ],
      "metadata": {
        "id": "caqWAvhbDlaT"
      },
      "execution_count": 449,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training and validation datasets.\n",
        "history = model.fit(\n",
        "  x=ds[\"train\"],\n",
        "  epochs=2,\n",
        "  validation_data=ds[\"val\"]\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0pp1505xKXZR",
        "outputId": "f594132e-90cb-40f8-8e7d-5ebfb520f7d2"
      },
      "execution_count": 451,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/2\n",
            "6/6 [==============================] - 1s 149ms/step - loss: 3.8563 - val_loss: 3.9292\n",
            "Epoch 2/2\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 3.8491 - val_loss: 3.9227\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate model.\n",
        "model.evaluate(ds[\"test\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XK6dnmiXKqB-",
        "outputId": "4783b4b6-fa42-4817-c833-5d12ddd95b97"
      },
      "execution_count": 452,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 0s 46ms/step - loss: 3.8848\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3.884826898574829"
            ]
          },
          "metadata": {},
          "execution_count": 452
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6PQ-6GpALAQE"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}